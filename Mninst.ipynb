{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('dsp': conda)"
  },
  "interpreter": {
   "hash": "c20777a8511cc243e1b38ac04983c4ba4c46d18e718680b1106ef75df6ba7904"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading digit-recognizer.zip to d:\\OneDrive - EPITA\\MSC AIS Course material\\Computer Vision\\Mninst\n",
      "\n",
      "\n",
      "  0%|          | 0.00/15.3M [00:00<?, ?B/s]\n",
      " 13%|█▎        | 2.00M/15.3M [00:00<00:01, 13.4MB/s]\n",
      " 26%|██▌       | 4.00M/15.3M [00:00<00:00, 15.5MB/s]\n",
      " 39%|███▉      | 6.00M/15.3M [00:00<00:01, 5.70MB/s]\n",
      " 52%|█████▏    | 8.00M/15.3M [00:01<00:00, 7.84MB/s]\n",
      " 65%|██████▌   | 10.0M/15.3M [00:01<00:00, 10.0MB/s]\n",
      " 78%|███████▊  | 12.0M/15.3M [00:01<00:00, 11.9MB/s]\n",
      " 91%|█████████▏| 14.0M/15.3M [00:01<00:00, 13.5MB/s]\n",
      "100%|██████████| 15.3M/15.3M [00:01<00:00, 11.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions download -c digit-recognizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# import mlflow\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "np.array((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]\n\n [[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]\n\n [[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]\n\n ...\n\n [[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]\n\n [[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]\n\n [[255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  ...\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]\n  [255. 255. 255. 255.]]]\n"
     ]
    }
   ],
   "source": [
    "original_array = np.loadtxt(\"test.txt\").reshape(300, 300,4)\n",
    "\n",
    "print(original_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = original_array[:,:,:-1].mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = abs(grayscale-255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[147., 144., 141., 138., 135., 132., 129., 127., 127., 127.],\n",
       "       [ 20.,  17.,  14.,  11.,   8.,   5.,   2.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "t[150:160, 150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAsPNG(original_array, 'testa.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[108., 111., 114., 117., 120., 123., 126., 128., 128., 128.],\n",
       "       [235., 238., 241., 244., 247., 250., 253., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.],\n",
       "       [255., 255., 255., 255., 255., 255., 255., 255., 255., 255.]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "original_array[150:160, 150:160,:-1].mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image=[]\n",
    "for i in range(300):\n",
    "    line=''\n",
    "    for j in range(300):\n",
    "        \n",
    "        if grayscale[i,j]<50:\n",
    "            line+=\"X\"\n",
    "        else:\n",
    "            line+=\".\"\n",
    "    image.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_test.txt', \"w\") as f:\n",
    "    for l in image:\n",
    "        f.write(l)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "len(image)"
   ]
  },
  {
   "source": [
    "# Loading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c9b501239e1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loading train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsp\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.csv'"
     ]
    }
   ],
   "source": [
    "# Loading train data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-cd5b68d6c9c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract label from train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract label from train data\n",
    "y = train_df['label']\n",
    "X = train_df.drop(columns=['label'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-321dadb4a72d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split the train data into TRAIN and VALID datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the train data into TRAIN and VALID datasets\n",
    "X_train, X_valid, y_train_classes, y_valid_classes = train_test_split(X, y, test_size=0.25, random_state=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b0251b70e163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# OneHotEncoding of the digits labels to match the Neural Network output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# OneHotEncoding of the digits labels to match the Neural Network output\n",
    "y_full = pd.get_dummies(y)\n",
    "y_train = pd.get_dummies(y_train_classes)\n",
    "y_valid = pd.get_dummies(y_valid_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "X_test = pd.read_csv('data/test.csv')\n",
    "X_test.head()"
   ]
  },
  {
   "source": [
    "# Regular Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "optimizer =  'adam'\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "985/985 [==============================] - 2s 3ms/step - loss: 0.2628 - accuracy: 0.9295 - val_loss: 0.2001 - val_accuracy: 0.9492\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.2626 - accuracy: 0.9313 - val_loss: 0.2061 - val_accuracy: 0.9484\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.2378 - accuracy: 0.9368 - val_loss: 0.1856 - val_accuracy: 0.9525\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.2340 - accuracy: 0.9377 - val_loss: 0.1895 - val_accuracy: 0.9522\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.2353 - accuracy: 0.9375 - val_loss: 0.1877 - val_accuracy: 0.9530\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.2220 - accuracy: 0.9417 - val_loss: 0.1999 - val_accuracy: 0.9459\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.2109 - accuracy: 0.9440 - val_loss: 0.1752 - val_accuracy: 0.9560\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.2073 - accuracy: 0.9451 - val_loss: 0.1781 - val_accuracy: 0.9576\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.2047 - accuracy: 0.9463 - val_loss: 0.1756 - val_accuracy: 0.9556\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.2031 - accuracy: 0.9468 - val_loss: 0.1987 - val_accuracy: 0.9518\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.2008 - accuracy: 0.9484 - val_loss: 0.1713 - val_accuracy: 0.9573\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1920 - accuracy: 0.9514 - val_loss: 0.1875 - val_accuracy: 0.9583\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1865 - accuracy: 0.9523 - val_loss: 0.1710 - val_accuracy: 0.9573\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1746 - accuracy: 0.9531 - val_loss: 0.1689 - val_accuracy: 0.9581\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1825 - accuracy: 0.9533 - val_loss: 0.1806 - val_accuracy: 0.9561\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1819 - accuracy: 0.9548 - val_loss: 0.1733 - val_accuracy: 0.9596\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1782 - accuracy: 0.9546 - val_loss: 0.1776 - val_accuracy: 0.9593\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1696 - accuracy: 0.9563 - val_loss: 0.1610 - val_accuracy: 0.9626\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1661 - accuracy: 0.9568 - val_loss: 0.1777 - val_accuracy: 0.9591\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1763 - accuracy: 0.9561 - val_loss: 0.1659 - val_accuracy: 0.9602\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1631 - accuracy: 0.9587 - val_loss: 0.1794 - val_accuracy: 0.9597\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.9558 - val_loss: 0.1776 - val_accuracy: 0.9597\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1639 - accuracy: 0.9579 - val_loss: 0.1821 - val_accuracy: 0.9579\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1526 - accuracy: 0.9617 - val_loss: 0.1752 - val_accuracy: 0.9603\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1567 - accuracy: 0.9597 - val_loss: 0.1712 - val_accuracy: 0.9619\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1484 - accuracy: 0.9621 - val_loss: 0.1685 - val_accuracy: 0.9634\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1547 - accuracy: 0.9621 - val_loss: 0.2081 - val_accuracy: 0.9626\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1412 - accuracy: 0.9637 - val_loss: 0.2056 - val_accuracy: 0.9587\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1475 - accuracy: 0.9643 - val_loss: 0.1734 - val_accuracy: 0.9624\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1488 - accuracy: 0.9629 - val_loss: 0.1904 - val_accuracy: 0.9631\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1572 - accuracy: 0.9632 - val_loss: 0.1887 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1565 - accuracy: 0.9638 - val_loss: 0.1676 - val_accuracy: 0.9644\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1482 - accuracy: 0.9641 - val_loss: 0.1804 - val_accuracy: 0.9627\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1463 - accuracy: 0.9650 - val_loss: 0.1870 - val_accuracy: 0.9612\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1470 - accuracy: 0.9639 - val_loss: 0.1780 - val_accuracy: 0.9635\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1468 - accuracy: 0.9642 - val_loss: 0.1771 - val_accuracy: 0.9614\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1418 - accuracy: 0.9660 - val_loss: 0.2115 - val_accuracy: 0.9576\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1429 - accuracy: 0.9655 - val_loss: 0.1936 - val_accuracy: 0.9567\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 6s 7ms/step - loss: 0.1486 - accuracy: 0.9657 - val_loss: 0.1706 - val_accuracy: 0.9639\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 7s 7ms/step - loss: 0.1471 - accuracy: 0.9645 - val_loss: 0.1806 - val_accuracy: 0.9622\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1394 - accuracy: 0.9670 - val_loss: 0.1934 - val_accuracy: 0.9607\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1418 - accuracy: 0.9682 - val_loss: 0.1839 - val_accuracy: 0.9643\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 3s 4ms/step - loss: 0.1394 - accuracy: 0.9675 - val_loss: 0.1793 - val_accuracy: 0.9649\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1333 - accuracy: 0.9673 - val_loss: 0.1873 - val_accuracy: 0.9611\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1357 - accuracy: 0.9687 - val_loss: 0.1912 - val_accuracy: 0.9636\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1335 - accuracy: 0.9693 - val_loss: 0.1687 - val_accuracy: 0.9654\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1347 - accuracy: 0.9679 - val_loss: 0.1969 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1249 - accuracy: 0.9705 - val_loss: 0.1997 - val_accuracy: 0.9620\n",
      "Epoch 49/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1267 - accuracy: 0.9691 - val_loss: 0.1727 - val_accuracy: 0.9634\n",
      "Epoch 50/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1282 - accuracy: 0.9703 - val_loss: 0.1866 - val_accuracy: 0.9646\n",
      "Epoch 51/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1298 - accuracy: 0.9692 - val_loss: 0.2001 - val_accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1340 - accuracy: 0.9695 - val_loss: 0.2016 - val_accuracy: 0.9643\n",
      "Epoch 53/100\n",
      "985/985 [==============================] - 4s 5ms/step - loss: 0.1318 - accuracy: 0.9690 - val_loss: 0.2364 - val_accuracy: 0.9576\n",
      "Epoch 54/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1383 - accuracy: 0.9682 - val_loss: 0.2108 - val_accuracy: 0.9610\n",
      "Epoch 55/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1195 - accuracy: 0.9717 - val_loss: 0.1990 - val_accuracy: 0.9642\n",
      "Epoch 56/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1291 - accuracy: 0.9701 - val_loss: 0.2198 - val_accuracy: 0.9610\n",
      "Epoch 57/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1363 - accuracy: 0.9678 - val_loss: 0.2041 - val_accuracy: 0.9624\n",
      "Epoch 58/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1326 - accuracy: 0.9701 - val_loss: 0.1966 - val_accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "985/985 [==============================] - 3s 4ms/step - loss: 0.1253 - accuracy: 0.9722 - val_loss: 0.1898 - val_accuracy: 0.9621\n",
      "Epoch 60/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1299 - accuracy: 0.9691 - val_loss: 0.2136 - val_accuracy: 0.9606\n",
      "Epoch 61/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1286 - accuracy: 0.9711 - val_loss: 0.2133 - val_accuracy: 0.9623\n",
      "Epoch 62/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1187 - accuracy: 0.9714 - val_loss: 0.2158 - val_accuracy: 0.9638\n",
      "Epoch 63/100\n",
      "985/985 [==============================] - 3s 4ms/step - loss: 0.1393 - accuracy: 0.9703 - val_loss: 0.2323 - val_accuracy: 0.9619\n",
      "Epoch 64/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1188 - accuracy: 0.9727 - val_loss: 0.2035 - val_accuracy: 0.9644\n",
      "Epoch 65/100\n",
      "985/985 [==============================] - 3s 4ms/step - loss: 0.1292 - accuracy: 0.9708 - val_loss: 0.2354 - val_accuracy: 0.9645\n",
      "Epoch 66/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1170 - accuracy: 0.9733 - val_loss: 0.2340 - val_accuracy: 0.9615\n",
      "Epoch 67/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1191 - accuracy: 0.9726 - val_loss: 0.2359 - val_accuracy: 0.9634\n",
      "Epoch 68/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1344 - accuracy: 0.9695 - val_loss: 0.1999 - val_accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1369 - accuracy: 0.9715 - val_loss: 0.2574 - val_accuracy: 0.9616\n",
      "Epoch 70/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1230 - accuracy: 0.9717 - val_loss: 0.2046 - val_accuracy: 0.9649\n",
      "Epoch 71/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1269 - accuracy: 0.9723 - val_loss: 0.2364 - val_accuracy: 0.9618\n",
      "Epoch 72/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1213 - accuracy: 0.9733 - val_loss: 0.2101 - val_accuracy: 0.9651\n",
      "Epoch 73/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1298 - accuracy: 0.9717 - val_loss: 0.2299 - val_accuracy: 0.9624\n",
      "Epoch 74/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1259 - accuracy: 0.9721 - val_loss: 0.2125 - val_accuracy: 0.9623\n",
      "Epoch 75/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1183 - accuracy: 0.9736 - val_loss: 0.2138 - val_accuracy: 0.9650\n",
      "Epoch 76/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.9747 - val_loss: 0.2108 - val_accuracy: 0.9656\n",
      "Epoch 77/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1076 - accuracy: 0.9754 - val_loss: 0.2123 - val_accuracy: 0.9665\n",
      "Epoch 78/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1159 - accuracy: 0.9741 - val_loss: 0.2192 - val_accuracy: 0.9629\n",
      "Epoch 79/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1259 - accuracy: 0.9718 - val_loss: 0.2090 - val_accuracy: 0.9616\n",
      "Epoch 80/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1256 - accuracy: 0.9736 - val_loss: 0.2438 - val_accuracy: 0.9646\n",
      "Epoch 81/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.9738 - val_loss: 0.2370 - val_accuracy: 0.9641\n",
      "Epoch 82/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1172 - accuracy: 0.9739 - val_loss: 0.2235 - val_accuracy: 0.9650\n",
      "Epoch 83/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1091 - accuracy: 0.9745 - val_loss: 0.2122 - val_accuracy: 0.9629\n",
      "Epoch 84/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1147 - accuracy: 0.9746 - val_loss: 0.2968 - val_accuracy: 0.9632\n",
      "Epoch 85/100\n",
      "985/985 [==============================] - 5s 5ms/step - loss: 0.1201 - accuracy: 0.9738 - val_loss: 0.2216 - val_accuracy: 0.9644\n",
      "Epoch 86/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1136 - accuracy: 0.9750 - val_loss: 0.2457 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1063 - accuracy: 0.9758 - val_loss: 0.2415 - val_accuracy: 0.9627\n",
      "Epoch 88/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1243 - accuracy: 0.9731 - val_loss: 0.2339 - val_accuracy: 0.9617\n",
      "Epoch 89/100\n",
      "985/985 [==============================] - 3s 3ms/step - loss: 0.1303 - accuracy: 0.9706 - val_loss: 0.2120 - val_accuracy: 0.9641\n",
      "Epoch 90/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1345 - accuracy: 0.9731 - val_loss: 0.1999 - val_accuracy: 0.9623\n",
      "Epoch 91/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1210 - accuracy: 0.9731 - val_loss: 0.2179 - val_accuracy: 0.9622\n",
      "Epoch 92/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1129 - accuracy: 0.9741 - val_loss: 0.2635 - val_accuracy: 0.9629\n",
      "Epoch 93/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1115 - accuracy: 0.9764 - val_loss: 0.2306 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.9756 - val_loss: 0.2309 - val_accuracy: 0.9623\n",
      "Epoch 95/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1158 - accuracy: 0.9746 - val_loss: 0.2045 - val_accuracy: 0.9644\n",
      "Epoch 96/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1125 - accuracy: 0.9752 - val_loss: 0.2477 - val_accuracy: 0.9634\n",
      "Epoch 97/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1054 - accuracy: 0.9753 - val_loss: 0.2271 - val_accuracy: 0.9641\n",
      "Epoch 98/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.9749 - val_loss: 0.2417 - val_accuracy: 0.9614\n",
      "Epoch 99/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1108 - accuracy: 0.9769 - val_loss: 0.2353 - val_accuracy: 0.9650\n",
      "Epoch 100/100\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1066 - accuracy: 0.9772 - val_loss: 0.2384 - val_accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[ 983    0    2    2    0    0    8    1   19    0]\n [   0 1173    7    2    2    0    2    0    4    0]\n [   3    1 1042    7    0    0    2    8   13    1]\n [   0    1    9 1018    0   11    0    9   17    5]\n [   3    6    1    0  998    1    5    1    6   13]\n [   1    0    1    9    1  897    6    1   12    2]\n [   1    1    0    0    0    4 1033    0    5    0]\n [   3    6   12    0    3    2    0 1095    1    7]\n [   4    8    6    7    2    7   14    0  936   11]\n [   4    3    3    7   10    9    0   19   15  946]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix for VALID dataset\n",
    "valid_preds = np.argmax(model.predict(X_valid),axis=-1)\n",
    "print(tf.math.confusion_matrix(y_valid_classes, valid_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "5            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n    <tr>\n      <th>ImageId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Prepare submission CSV filed\n",
    "submission = pd.read_csv('data/sample_submission.csv', index_col='ImageId')\n",
    "test_preds = np.argmax(model.predict(X_test),axis=-1) # predictions on TEST dataset\n",
    "submission['Label'] = test_preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export submission to CSV\n",
    "submission.to_csv('data/submission_NN.csv')"
   ]
  },
  {
   "source": [
    "# Convolution NN\n",
    "To use Convolutional Neural Network, the dataset needs to be reshaped to the original 28x28 pixels images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping all datasets to suit CNN\n",
    "arr_train = np.array(X_train)\n",
    "arr_valid = np.array(X_valid)\n",
    "arr_test = np.array(X_test)\n",
    "\n",
    "X_train_arr = arr_train.reshape((arr_train.shape[0], 28, 28, 1))\n",
    "X_valid_arr = arr_valid.reshape((arr_valid.shape[0], 28, 28,1 ))\n",
    "X_test_arr = arr_test.reshape((arr_test.shape[0], 28, 28,1))\n",
    "\n",
    "\n",
    "# Normalised data\n",
    "X_train_norm = X_train_arr/255\n",
    "X_valid_norm = X_valid_arr/255\n",
    "X_test_norm = X_test_arr/255\n",
    "# X_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "a=np.zeros((28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"image\", original_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### 100 epochs :0.97164 (on test), 0.9729 on valid\n",
    "# CNN_model = tf.keras.models.Sequential([\n",
    "#     Conv2D(2,3, activation='relu', input_shape=(28,28,1)),\n",
    "#     MaxPooling2D((2,2)),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# 67 epochs : 0.97489 on test, 0.9772 on valid\n",
    "# CNN_model = tf.keras.models.Sequential([\n",
    "#     Conv2D(2,3, activation='relu', input_shape=(28,28,1)),\n",
    "#     MaxPooling2D((2,2)),\n",
    "#     Conv2D(2,3, activation='relu' ),\n",
    "#     Flatten(),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "\n",
    "# 100 epochs Score : 0.9796 on valid\n",
    "CNN_model = tf.keras.models.Sequential([\n",
    "    Conv2D(2,2, activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(2,2, activation='relu' ),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 27, 27, 2)         10        \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 2)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 12, 12, 2)         18        \n_________________________________________________________________\nflatten (Flatten)            (None, 288)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               147968    \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 544,550\nTrainable params: 544,550\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "optimizer =  'adam'\n",
    "\n",
    "CNN_model.compile(loss=loss_function, optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with original values (0-255)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "#best_valid:  0.98305\n",
    "# simple early stopping\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5) # Not used, allow to stop training if the validation loss does not decrease in a certain number of epochs (\"patience\" parameter)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True) # Save the model with best validation accuracy\n",
    "# fit model\n",
    "history = CNN_model.fit(X_train_arr,y_train, epochs=epochs, validation_data=(X_valid_arr, y_valid), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ss: 0.1268 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.97990 to 0.98200, saving model to best_model_norm.h5\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 18s 18ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.1232 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.98200\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.1343 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.98200\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.1452 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98200\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.1144 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98200\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1452 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98200 to 0.98229, saving model to best_model_norm.h5\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1275 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98229\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.1190 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98229\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.1450 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98229\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.1195 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98229\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 16s 17ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.1125 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98229\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1184 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98229\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 17s 17ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.1484 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98229\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 20s 20ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1197 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98229\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.1460 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98229\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 18s 18ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1155 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98229\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.1123 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98229\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1220 - val_accuracy: 0.9804\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98229\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 14s 15ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.1245 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98229\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.1325 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98229\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.1396 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.98229 to 0.98371, saving model to best_model_norm.h5\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 0.1189 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98371\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.1138 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98371\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 13s 14ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1411 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98371\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1457 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.98371\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 0.1232 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98371\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.1124 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98371\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.1412 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98371\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.1314 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98371\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.1108 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98371\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 14s 15ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.1336 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98371\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.1397 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98371\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.1268 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98371\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.1334 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98371\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1293 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98371\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.1202 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98371\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 21s 22ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1541 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98371\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 15s 16ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.1374 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98371\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.1959 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98371\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.1438 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98371\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.1433 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98371\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1297 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.98371\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.1543 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98371\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 15s 16ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.1186 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98371\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.1537 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98371\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.1409 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98371\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 11s 12ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.1297 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98371\n",
      "Epoch 49/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.1249 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98371\n",
      "Epoch 50/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1575 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98371\n",
      "Epoch 51/100\n",
      "985/985 [==============================] - 11s 12ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1342 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.98371\n",
      "Epoch 52/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.1350 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.98371\n",
      "Epoch 53/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.1118 - val_accuracy: 0.9789\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.98371\n",
      "Epoch 54/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1259 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.98371\n",
      "Epoch 55/100\n",
      "985/985 [==============================] - 11s 11ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.1408 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.98371\n",
      "Epoch 56/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.1427 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.98371\n",
      "Epoch 57/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.1298 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.98371\n",
      "Epoch 58/100\n",
      "985/985 [==============================] - 12s 13ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.1147 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.98371\n",
      "Epoch 59/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1300 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.98371\n",
      "Epoch 60/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.1407 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.98371\n",
      "Epoch 61/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1679 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.98371\n",
      "Epoch 62/100\n",
      "985/985 [==============================] - 12s 13ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.1574 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.98371\n",
      "Epoch 63/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.1425 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.98371\n",
      "Epoch 64/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.1465 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.98371\n",
      "Epoch 65/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.1346 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.98371\n",
      "Epoch 66/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.1399 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.98371\n",
      "Epoch 67/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1152 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.98371\n",
      "Epoch 68/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.1363 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.98371\n",
      "Epoch 69/100\n",
      "985/985 [==============================] - 14s 15ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.1664 - val_accuracy: 0.9804\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.98371\n",
      "Epoch 70/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.1578 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.98371\n",
      "Epoch 71/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1513 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.98371\n",
      "Epoch 72/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.1443 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.98371\n",
      "Epoch 73/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.1175 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.98371\n",
      "Epoch 74/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.1352 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.98371\n",
      "Epoch 75/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1418 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.98371\n",
      "Epoch 76/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.1351 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.98371\n",
      "Epoch 77/100\n",
      "985/985 [==============================] - 16s 17ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.1208 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.98371\n",
      "Epoch 78/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.1495 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.98371\n",
      "Epoch 79/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.1642 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.98371\n",
      "Epoch 80/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.1242 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.98371\n",
      "Epoch 81/100\n",
      "985/985 [==============================] - 15s 16ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.1617 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.98371\n",
      "Epoch 82/100\n",
      "985/985 [==============================] - 15s 16ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 0.1515 - val_accuracy: 0.9789\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.98371\n",
      "Epoch 83/100\n",
      "985/985 [==============================] - 16s 16ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1328 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.98371\n",
      "Epoch 84/100\n",
      "985/985 [==============================] - 15s 16ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.1410 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.98371\n",
      "Epoch 85/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.1138 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.98371\n",
      "Epoch 86/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.2192 - val_accuracy: 0.9786\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.98371\n",
      "Epoch 87/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.1510 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.98371\n",
      "Epoch 88/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.1311 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.98371\n",
      "Epoch 89/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.1803 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.98371\n",
      "Epoch 90/100\n",
      "985/985 [==============================] - 14s 15ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 0.1681 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.98371\n",
      "Epoch 91/100\n",
      "985/985 [==============================] - 14s 14ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.1397 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.98371\n",
      "Epoch 92/100\n",
      "985/985 [==============================] - 15s 15ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.1338 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.98371\n",
      "Epoch 93/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.1394 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.98371\n",
      "Epoch 94/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.1621 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.98371\n",
      "Epoch 95/100\n",
      "985/985 [==============================] - 13s 14ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1884 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.98371\n",
      "Epoch 96/100\n",
      "985/985 [==============================] - 13s 13ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.1550 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.98371\n",
      "Epoch 97/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1657 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.98371\n",
      "Epoch 98/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.1750 - val_accuracy: 0.9804\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.98371\n",
      "Epoch 99/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1834 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.98371\n",
      "Epoch 100/100\n",
      "985/985 [==============================] - 12s 12ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.1818 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.98371\n"
     ]
    }
   ],
   "source": [
    "# Training model with normalised data\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "#best_valid:  0.98267 (100 epochs)\n",
    "# simple early stopping\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('best_model_norm.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# fit model\n",
    "history = CNN_model.fit(X_train_norm,y_train, epochs=epochs, validation_data=(X_valid_norm, y_valid), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c6a1516440ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhist_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.sort_values(\"val_accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model saved during fitting\n",
    "# from keras.models import load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_names = ['best_model.h5', 'best_model_norm.h5', \"../CNN_1.0_98781.h5\"]\n",
    "current_model = model_names[2]\n",
    "saved_model = load_model(current_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_preds = np.argmax(saved_model.predict(X_test_arr),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Submission for original data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "5            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n    <tr>\n      <th>ImageId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv', index_col='ImageId')\n",
    "test_preds = np.argmax(saved_model.predict(X_test_arr),axis=-1)\n",
    "submission['Label'] = test_preds\n",
    "submission.to_csv('data/submission_CNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for VALID dataset\n",
    "valid_preds = np.argmax(saved_model.predict(X_valid_arr),axis=-1)\n",
    "print(tf.math.confusion_matrix(y_valid_classes, valid_preds))"
   ]
  },
  {
   "source": [
    "## Submission for normalised data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv', index_col='ImageId')\n",
    "test_preds = np.argmax(saved_model.predict(X_test_norm),axis=-1)\n",
    "submission['Label'] = test_preds\n",
    "submission.to_csv('data/submission_CNN_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for VALID dataset\n",
    "valid_preds = np.argmax(saved_model.predict(X_valid_norm),axis=-1)\n",
    "print(tf.math.confusion_matrix(y_valid_classes, valid_preds))"
   ]
  }
 ]
}